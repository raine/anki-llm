import OpenAI from 'openai';
import { z } from 'zod';
import chalk from 'chalk';
import { ankiRequest, NoteInfo } from '../anki-connect.js';
import {
  getProviderConfig,
  getApiKeyForModel,
  SupportedModel,
} from '../config.js';
import { calculateCost } from '../utils/llm-cost.js';
import { isAutoGeneratedField } from './util.js';
import { getLlmResponseManually } from '../utils/manual-llm.js';

export interface PromptGenerationCostInfo {
  inputTokens: number;
  outputTokens: number;
  totalCost: number;
}

/**
 * Generates a boilerplate prompt body with instructions and a one-shot example.
 */
function generateGenericPromptBody(fieldKeys: string[]): string {
  const exampleJson: Record<string, string> = {};
  for (const key of fieldKeys) {
    exampleJson[key] = `Example value for ${key}`;
  }

  // Format the example as an array element with proper indentation
  const arrayExample =
    '[\n' + JSON.stringify(exampleJson, null, 2).replace(/^/gm, '  ') + '\n]';

  return `You are an expert assistant who creates {count} distinct Anki flashcards for a vocabulary term.
The term to create cards for is: **{term}**

IMPORTANT: Your output must be a single, valid JSON array of objects and nothing else.
Do not include any explanation, markdown formatting, or additional text.
Each object in the array should represent a unique flashcard.
All field values must be strings.
For fields that require formatting (like lists or emphasis), generate a single string containing well-formed HTML.

Follow the structure and HTML formatting shown in this example precisely:

\`\`\`json
${arrayExample}
\`\`\`

Return only a valid JSON array matching this structure. Ensure you generate {count} varied and high-quality cards.

Tips for creating high-quality cards:
- Provide clear, concise definitions or translations
- Include natural, contextual examples that highlight different nuances of the term
- Ensure each card offers a unique perspective, context, or usage example
- Use HTML tags like <b>, <i>, <ul>, <li> for formatting when helpful
- For language learning: include pronunciation guides if relevant
- Keep the content focused and easy to review`;
}

/**
 * Generates a contextual prompt body using an LLM by analyzing sample cards.
 */
async function generateContextualPromptBody(
  deckName: string,
  sampleCards: Array<Record<string, string>>,
  fieldKeys: string[],
  userModel?: string,
  temperature?: number,
  isCopyMode?: boolean,
): Promise<{ body: string; costInfo?: PromptGenerationCostInfo }> {
  // Determine model
  let model: string;

  if (userModel) {
    model = userModel;
  } else {
    // Auto-detect based on available API key
    const useGemini = Boolean(process.env.GEMINI_API_KEY);
    model = useGemini ? 'gemini-2.5-flash' : 'gpt-5';
  }

  // Build the meta-prompt
  const metaPrompt = `You are an expert prompt engineer creating a prompt template for another AI.
Your goal is to generate a helpful and flexible prompt body that instructs an AI to create multiple new Anki cards that match the general style of the provided examples.

**IMPORTANT CONTEXT:**
- The user's deck is named "${deckName}".
- You are working with a very small sample of existing cards.
- Your task is to infer the *likely principles and general style*, not to codify every detail as a strict rule. Prioritize patterns that are consistent across multiple examples and ignore coincidences.

**EXISTING CARD EXAMPLES:**
\`\`\`json
${JSON.stringify(sampleCards, null, 2)}
\`\`\`

**YOUR TASK:**

**Step 1: Gentle Analysis**
Analyze the examples to understand the deck's high-level principles:

1. **Purpose & Style**: What is the likely subject matter and learning goal (e.g., conversational Japanese, medical terminology)?
2. **Content Principles**: What kind of information is typically included in fields like explanations or notes? Look for recurring themes (e.g., formal vs. informal usage, common mistakes, collocations). Distinguish between what seems essential versus what is helpful but optional.
3. **Formatting Conventions**: How is HTML used for emphasis and structure?
   - What is the *purpose* of tags like \`<b>\` or \`<ul>\`?
   - For linguistic formatting (like Japanese furigana \`Êº¢Â≠ó[„Åã„Çì„Åò]\`), identify the general pattern but **avoid creating overly strict spacing rules** from this small sample. Focus on high-confidence patterns only.

**Step 2: Generate a Flexible Prompt Body for MULTIPLE Cards**
Using your analysis, generate a prompt body that guides the AI to create a batch of cards that *fit the spirit* of the examples, while allowing for natural variation.

1. **Persona & Goal**: Start with a concise instruction for the AI, mentioning the deck's purpose and that it should generate **{count} distinct cards**. This placeholder is critical. For example: "You are an expert assistant who creates {count} distinct Anki flashcards for...".

2. **Term Placeholder**: Include a natural sentence that introduces the term/phrase using the **{term}** placeholder. For example: "The term to create cards for is: **{term}**".

3. **One-Shot Example (Array Format)**: Provide a single, plausible, **NEW** example inside a JSON array code block. This example should be a good demonstration of the deck's style. The JSON keys must be exactly: ${fieldKeys.join(', ')}. The output format must be \`[ { ...card_object...} ]\`.

4. **Boilerplate**: Include the standard instruction: "IMPORTANT: Your output must be a single, valid JSON array of objects and nothing else. Do not include any explanation, markdown formatting, or additional text. All field values must be strings."

5. **Stylistic & Diversity Guidelines (Not Strict Rules)**:
   - Create sections with headings like "Formatting Guidelines" and "Content Guidelines".
   - Phrase instructions as recommendations, not commands. Use words like "Generally," "Typically," "Aim to," "Consider including."
   - **Add instructions to encourage diversity**: "Ensure each card offers a unique perspective on the term, such as a different definition, context, or example sentence."
   - **Good Example**: "Typically, use \`<b>\` tags to highlight the main term within example sentences."
   - **Bad Example**: "You must always bold the second word of every sentence."
   - If a field was often empty in the samples, suggest its purpose rather than mandating it be empty. Example: "The 'notes' field is optional but can be used for extra cultural context."
   - For complex formatting like furigana, provide a single good example and a brief, high-level description of the pattern. Avoid detailed CORRECT/INCORRECT lists unless a pattern is exceptionally clear and consistent across all samples.

**OUTPUT FORMAT:**
Return ONLY the raw text for the prompt body. Do NOT include frontmatter or explanations about your process.`;

  // Handle copy mode - manual workflow
  if (isCopyMode) {
    console.log(
      chalk.cyan('\nüìã Running in manual copy mode for prompt generation.'),
    );
    const generatedPrompt = await getLlmResponseManually(metaPrompt);
    if (!generatedPrompt) {
      throw new Error('Empty response from LLM');
    }
    return { body: generatedPrompt };
  }

  // Get provider configuration and API key for the model
  const providerConfig = getProviderConfig(model);
  const apiKey = getApiKeyForModel(model);

  if (!apiKey) {
    throw new Error(
      `${providerConfig.recommendedApiKeyEnv} environment variable is required for model '${model}'`,
    );
  }

  const client = new OpenAI({
    apiKey,
    baseURL: providerConfig.baseURL,
  });

  try {
    const response = await client.chat.completions.create({
      model,
      messages: [
        {
          role: 'user',
          content: metaPrompt,
        },
      ],
      ...(temperature !== undefined && { temperature }),
    });

    const generatedPrompt = response.choices[0]?.message?.content?.trim();
    if (!generatedPrompt) {
      throw new Error('Empty response from LLM');
    }

    // Extract cost information
    const usage = response.usage;
    let costInfo: PromptGenerationCostInfo | undefined;

    if (usage) {
      const inputTokens = usage.prompt_tokens ?? 0;
      const outputTokens = usage.completion_tokens ?? 0;

      // Validate model before calculating cost
      const modelResult = SupportedModel.safeParse(model);
      if (modelResult.success) {
        const totalCost = calculateCost(
          modelResult.data,
          inputTokens,
          outputTokens,
        );
        costInfo = { inputTokens, outputTokens, totalCost };
      }
    }

    return { body: generatedPrompt, costInfo };
  } catch (error) {
    // Enhanced error logging for debugging
    let errorMessage = 'LLM API call failed';
    if (error instanceof Error) {
      errorMessage = error.message;
      // Log additional details if available
      if ('status' in error) {
        console.error('   Status code:', error.status);
      }
      if ('error' in error) {
        console.error('   Error details:', JSON.stringify(error.error));
      }
    }
    throw new Error(`LLM API call failed: ${errorMessage}`);
  }
}

/**
 * Orchestrates the creation of the prompt body.
 * Tries to generate a "smart" contextual prompt. If it fails, falls back to a generic one.
 */
export async function createPromptContent(
  deckName: string,
  initialFieldMap: Record<string, string>,
  model?: string,
  temperature?: number,
  isCopyMode?: boolean,
): Promise<{
  body: string;
  finalFieldMap: Record<string, string>;
  costInfo?: PromptGenerationCostInfo;
}> {
  try {
    // 1. Find notes in the deck
    const noteIds = await ankiRequest('findNotes', z.array(z.number()), {
      query: `deck:"${deckName}"`,
    });

    if (noteIds.length < 1) {
      throw new Error('No cards found in deck to analyze.');
    }

    // 2. Sample cards, preferring those with populated fields
    // Fetch ALL notes from the deck to find the best examples
    console.log(
      chalk.gray(
        `  Analyzing ${noteIds.length} card(s) to find best examples...\n`,
      ),
    );

    const allNotesInfo = await ankiRequest('notesInfo', z.array(NoteInfo), {
      notes: noteIds,
    });

    // Score each card by how many non-empty fields it has
    const scoredNotes = allNotesInfo.map((note) => {
      let score = 0;
      for (const ankiField of Object.values(initialFieldMap)) {
        const value = note.fields[ankiField]?.value || '';
        // Count non-empty, non-auto-generated fields
        if (value.trim() && !isAutoGeneratedField(value)) {
          score++;
        }
      }
      return { note, score };
    });

    // Sort by score (descending) and take top 5
    const sampleCount = Math.min(5, scoredNotes.length);
    const topNotes = scoredNotes
      .sort((a, b) => b.score - a.score)
      .slice(0, sampleCount)
      .map((item) => item.note);

    console.log(
      chalk.gray(
        `  Selected ${sampleCount} card(s) with most populated fields...\n`,
      ),
    );

    if (topNotes.length === 0) {
      throw new Error(
        'Found cards, but none have usable content for analysis.',
      );
    }

    // 3. Filter out auto-generated fields from the map
    const finalFieldMap: Record<string, string> = {};
    const skippedFields: string[] = [];

    for (const [jsonKey, ankiField] of Object.entries(initialFieldMap)) {
      // Check sample to see if this field contains auto-generated content
      const sampleValue = topNotes[0]?.fields[ankiField]?.value || '';
      const isAutoGenerated = isAutoGeneratedField(sampleValue);

      if (!isAutoGenerated) {
        finalFieldMap[jsonKey] = ankiField;
      } else {
        skippedFields.push(ankiField);
      }
    }

    if (skippedFields.length > 0) {
      console.log(
        chalk.gray(
          `  Skipping auto-generated field(s): ${skippedFields.join(', ')}\n`,
        ),
      );
    }

    // 4. Format examples using the fieldMap keys
    const sampleCards = topNotes.map((note) => {
      const card: Record<string, string> = {};
      for (const [jsonKey, ankiField] of Object.entries(finalFieldMap)) {
        card[jsonKey] = note.fields[ankiField]?.value || '';
      }
      return card;
    });

    // 5. Call LLM to generate contextual prompt
    const { body, costInfo } = await generateContextualPromptBody(
      deckName,
      sampleCards,
      Object.keys(finalFieldMap),
      model,
      temperature,
      isCopyMode,
    );

    console.log(chalk.green('‚úì Smart prompt generated successfully!\n'));

    return { body, finalFieldMap, costInfo };
  } catch (error) {
    console.log(
      chalk.yellow(
        '\n‚ö†Ô∏è  Could not generate smart prompt. Falling back to generic template.',
      ),
    );
    console.log(
      chalk.gray(
        `   Reason: ${error instanceof Error ? error.message : 'Unknown error'}\n`,
      ),
    );
    const body = generateGenericPromptBody(Object.keys(initialFieldMap));
    return { body, finalFieldMap: initialFieldMap };
  }
}
